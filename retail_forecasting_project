---
title: "Retail Forecasting Project"
author: "Nhi (Chelsea) Le - ID: 30100259"
date: "6/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

**Objective:** To forecast a real time series using ETS and ARIMA models.

**Data:** Retail trade turnover for Pharmaceutical, cosmetic and toiletry goods retailing in New South Wales, in million AUD, with monthly frequency from April 1982 to December 2017. 

```{r}
library(fpp3)
library(kableExtra)
library(tidyverse)

set.seed(30100259, sample.kind="default")
myseries <- aus_retail %>%
  filter(
    `Series ID` == sample(aus_retail$`Series ID`,1),
    Month < yearmonth("2018 Jan")
  ) %>%
  select(Month, Turnover) %>% 
  rename(month = Month, turnover = Turnover)
myseries %>% head(10) %>% kable()
```

# 1. Statistical features of the original data.


* Summary of the data

```{r}
summary(myseries) 
```

```{r}
myseries %>% ggplot() + 
  geom_density(aes(x = turnover, color = "turnover"), fill = "blue", alpha = 0.1, size = 1) + 
  geom_vline(aes(color = "mean", xintercept = 184.8)) +
  labs(title = "Distribution of turnover: New South Wales retail trade", subtitle = "Pharmaceutical, cosmetic and toiletry goods retailing") +
  ylab("Density") + 
  xlab("Turnover (million AUD)") + 
  theme_light()
```

* The mean turnover for this series is 184.8 million AUD. 
* Distribution of turnover is positively skewed. 

```{r}
myseries %>% 
  autoplot(turnover) + 
  labs(title = "Timeseries plot: New South Wales retail trade turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods retailing") +
  ylab("Turnover (million AUD)") + 
  xlab("Time") + 
  theme_light()
```

* There is a clear upward trend throughout the whole time series (suggesting that turnover for this sector in NSW tends to increase with time), with evidence of cyclic behaviour of rises and falls that are not of fixed frequency, spanning 8 - 10 years and more. 

* In around 1997, there was a dip in turnover for Pharmaceutical, cosmetic and toiletry goods retailing	in NSW, probably due to the Asian financial crisis at that time; a significant decrease in 2008 due to the GFC and a smaller dip in 2015 due to the slight recession Australia was experiencing that year. 

* Overall, turnover does increase through time, and more so during recent years (due to the overall improvements in the economy and people's increased living standards), and tends to decrease during recessions. 

```{r}
myseries %>% 
  gg_season(turnover) + 
  labs(title = "Seasonal plot: New South Wales retail trade turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods retailing") +
  ylab("Turnover (million AUD)") + 
  xlab("Time") + 
  theme_classic()
```

* This seasonal plot shows that there is a significant increase in turnover for Pharmaceutical, cosmetic and toiletry goods retailing	in NSW in December of every year, probably due to increased demand during the holiday season and people stocking up before the end of financial year. 

* There is also a slight dip in turnover for February, April, June, September, November and then usually a jump in turnover for March, May, July, August, October. This might be due to the difference in days of each month (fewer days means slightly lower turnover). 

```{r}
myseries %>% 
  gg_subseries(turnover) + 
labs(title = "Seasonal subseries plot: New South Wales retail trade turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods retailing") +
  ylab("Turnover (million AUD)") + 
  xlab("Time")
```

* This seasonal subseries plot allows us to more clearly see the seasonal patterns discussed above. 

* The mean turnover for December did actually increase significantly compared to other months' turnovers. 

* The slight rises and falls in the remaining months (due to differences in number of days) as detailed in the previous description are also revealed here. 

* We can also see the evident upward trend in turnover throughout the whole time period with this plot as well.


```{r}
myseries %>% gg_tsdisplay(turnover, plot_type = 'partial', lag_max = 60) + 
labs(title = "Time series properties plots: New South Wales retail trade turnover", subtitle = "Original data") 
```

* Clearly, this series is not stationary as it is strongly trended. Besides looking at the time plot of the data, its ACF also decays to 0 very slowly, which indicates strong persistence. 
* Its PACF shows a significant spike at lag 1, suggesting strong autocorrelation. There are also spikes outside the boundaries at lags 13, 25, 37, etc. We expect there to be monthly seasonality due to the frequency of the data. 

```{r}
myseries %>% features(turnover, ljung_box, lag =24) 
```
* Performing the Ljung-Box test with 24 lags on this series before making any transformations yields a p-value of 0, suggesting significant and persistent autocorrelations.

# 2. Transformations and differencing used.

## Transformation: 

* The variation appears proportional to the level of the series, so a Box-Cox transformation may be useful.

- **Using log transformation (i.e. $\lambda$ = 0):** 

```{r}
myseries %>% autoplot(log(turnover)) + 
  labs(title = "Turnover for NSW's pharmaceutical, cosmetic and toiletry goods retailing", subtitle = "With log transformation, i.e. lambda = 0") + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light()
```

* A log transformation (Box-Cox $\lambda$ = 0) seems to have removed a majority of the heteroskedasticity in the data. 

- **Using Guerrero method with lambda guerrero:** 

```{r}
guerrero_myseries <- myseries %>% 
  features(turnover, features = guerrero) %>% 
  pull(lambda_guerrero) 

myseries %>% autoplot(box_cox(turnover, guerrero_myseries)) + 
  labs(title = "Turnover for NSW's pharmaceutical, cosmetic and toiletry goods retailing", subtitle = "After transformation with guerrero lambda = 0.04394935") + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light()
```

* The Guerrero method suggests a value close to 0, which is very similar to doing a natural log transformation. 

* After trying out different $\lambda$ values for transforming my data, I've decided on log transformation, i.e. $\lambda = 0$ because it does a decently good job of removing a majority of the heteroskedasticity in the orginal data. As seen in the above plot, deviations from the mean throughout the whole period, after log transformation, are quite constant, maybe still a little higher in the middle, but not too much. That being said, this particular problem does occur with other lambda values so if our goal is not to obtain perfectly uniform variances then it should not be the main issue. 

* Moreover, log transformation also has greater interpretability than other $\lambda$ values as it can be directly interpreted as the percentage change in Y (i.e. turnover in this case) which will be of more importance to us in the end than perfect homoskedasticity. 

* So in a nutshell, **log transformation, or Box Cox $\lambda = 0$ is chosen for this particular time series.** 

## Differencing: 

**Unit-root test: Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test:**

$H_0$: the data is stationary and non-seasonal. 
$H_1$: the data is not stationary and seasonal. 


```{r}
myseries %>% 
  features(turnover, unitroot_kpss)
```

* p-value = 0.01 < $\alpha = 0.05$. Hence, we reject the null of the KPSS test at 5% significance level and conclude that there is sufficient evidence to suggest that the turnover series is not stationary and is seasonal, which suggests that differencing is required. 

* We first check if seasonal differencing is required: 

```{r}
myseries %>% mutate(log_turnover = log(turnover)) %>% 
  features(log_turnover, unitroot_nsdiffs)
```

* This suggests that after log transformation, one seasonal differencing is needed. 

```{r}
myseries %>% mutate(log_turnover = difference(log(turnover),12)) %>%
  features(log_turnover, unitroot_ndiffs)
```

* This suggests that after log transformation and one seasonal differencing, we do not need to do first difference. The data at this stage, after log transformation and one seasonal difference, should be stationary. Let's check if this is the case: 

```{r}
myseries %>% 
  mutate(sdiff_log_turnover = turnover %>% log() %>% difference(12)) %>% 
  gg_tsdisplay(sdiff_log_turnover, plot_type = 'partial', lag_max = 60) +
  labs(title = "Time series properties plots: New South Wales retail trade turnover", subtitle = "After log transformation and one seasonal difference of the original data") 
```

* Despite slightly higher fluctuations around the mean during certain months, the series appears to be rather stationary. In other words, there seem to be no predictable patterns in the long-term. 

* The ACF dies out in a damped sine-wave manner, suggesting that the transformation and seasonal difference have removed the problem of non-stationary mean. 

* The PACF now shows significant spikes at lag 1, 2, and at seasonal lags 12, 24, 36, which can be dealt with later. 

```{r}
myseries %>% features(difference(log(turnover),12), unitroot_kpss)
```

* p-value for the unit root test is now = 0.1 > $\alpha = 0.05$. Hence we no longer reject the null of the KPSS test at 5% significance level and conclude that the turnover series, after applying log transformation and one seasonal differencing, is now stationary. 

# 3. Methodology used to create a short-list of appropriate ARIMA models and ETS models.

* First, we create a test set containing the last 24 months of the data and a train set containing the remaining observations not included in the test set. We will train our model on the train set and evaluate on the test set. 

```{r}
test <- myseries %>% filter(year(month) > 2015)
train <- myseries %>% filter(year(month) < 2016)
```

* AICc can be used to compare between ETS models and ARIMA models with the same order of differencing. The idea behind AICc is to penalise the fit of the model with the number of parameters that are being estimated. Minimising AICc also minimises the errors in time series cross validation. Therefore, the lower the AICc, the better the model. 

## ETS models:

```{r}
myseries %>% autoplot(turnover) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "Turnover for NSW's pharmaceutical, cosmetic and toiletry goods retailing", subtitle = "Original data")
```

* From looking at the time series plot, we know that our model should take into account the **increasing trend**. There should also be **multiplicative seasonality** because the size of the seasonal fluctuations seems to increase with the level. 

* Therefore: 

1. The trend can be either "additive" or "damped", 

2.  The seasonality should be "multiplicative", 

3. The errors can be either "additive" or "multiplicative". (In this case, the errors can be "multiplicative" because my retail turnover data is positive and larger than 0.). However, since (A) errors with (M) seasonality can be unstable, we will not consider this combination moving forward. 

* The potential ETS models for my retail time series are therefore: 

1. ETS(M,A,M)
2. ETS(M,Ad,M)

* The automatic model suggested is ETS(M,Ad,M), which is also within our expectations. 

* Training the 2 potential ETS models on the train set: 

```{r}
ets_fit <- train %>% 
  model( MAM = ETS(turnover ~ error("M") + trend("A") + season("M")), 
        MAdM = ETS(turnover ~ error("M") + trend("Ad") + season("M")))

glance(ets_fit) %>% select(.model, AICc) %>% arrange(AICc) 
```

* In terms of AICc obtained from training on the train set, the best ETS model for my retail time series is ETS(M,Ad,M) with multiplicative errors, additive damped trend and multiplicative seasonality. 

* In terms of applying these models to the test set:

```{r}
ets_fit %>% forecast(h = 24) %>% accuracy(myseries) %>% arrange(RMSE)
```

* In terms of model performance on the test set, ETS(M,Ad,M) is also the better model, regardless of what statistic we use, but espectially RMSE where we have 32.90115 for ETS(M,Ad,M) < 42.71277 for ETS(M,A,M).

* Create a subseries with only recent observations so we will be able to see more clearly the different forecasts and prediction intervals that these models produce on the test set when plotting on a time graph: 

```{r}
myseries_recent <- myseries %>% filter(year(month) > 2010)
```

```{r}
ets_fit %>% forecast(h = 24) %>% autoplot(myseries_recent, alpha = 0.5) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS models")
```

* Visually, ETS(M,Ad,M) produces more accurate forecasts and narrower prediction intervals than ETS(M,A,M) when evaluating on the test set consisting of the last 24 months of the data.

* In contrast, ETS(M,A,M) produces unreasonably wide prediction intervals (which will increase even more in the future).

* **In this case, for my data, I would prefer ETS(M,Ad,M) because:** 

- There is not a big difference between ETS(M,Ad,M) and ETS(M,A,M) when it comes to point forecasts. But clearly, ETS(M,A,M)'s prediction intervals are too wide, especially if we forecast further into the future. 

```{r}
ets_fit %>% forecast(h = 96) %>% autoplot(myseries_recent, alpha = 0.5) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "8-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS models")
```

- ETS(M,Ad,M) has lower AICc when fitting on the train set.

- ETS(M,Ad,M) also performs better on the test set, especially in terms of RMSE.

* For these reasons, from a forecasting perspective, **ETS(M,Ad,M) is the best ETS model for our data.** 

## ARIMA models: 

* For ARIMA models, we will need to to some residual diagnostics by looking at the ACF for signs of autocorrelations as well as doing the Ljung-Box test. 

* While the ACF can be useful in portraying if there are any significant autocorrelations remaining in the residuals, it can sometimes give a false positive: we may conclude that the residuals have some remaining autocorrelation, when in fact they do not. To overcome this problem, the Ljung-Box test - referred to as a Portmanteau test - can be utilised: 

$H_0$: residuals are indistinguishable from a white noise series.


$H_1$: residuals do not resemble a white noise series. 

* We reject the null for the Ljung-Box test at 5% significance level if lb_pvalue < 0.5. 

* For this data, since the frequency is monthly, we will perform the Ljung-Box test with 24 lags (12x2) and dof depending on the number of parameters being estimated by each model.

* A forecasting method wherein the residuals are correlated or do not have zero mean can be improved further so all the important information has been used in computing forecasts and the forecasts are not biased.  

```{r}
myseries %>% 
  mutate(sdiff_log_turnover = turnover %>% log() %>% difference(12)) %>% 
  gg_tsdisplay(sdiff_log_turnover, plot_type = 'partial', lag_max = 60) +
  labs(title = "Time series properties plots: New South Wales retail trade turnover", subtitle = "After log transformation and one seasonal difference of the original data") 
```


* ACF dies out in a damped sine-wave manner, in other words, is sinusoidal. 

* PACF: In the non-seasonal lags, there are two significant spikes at lags 1 and 2, suggesting a possible non-seasonal AR(2) component, and significant spikes at seasonal lags 12, 24, 36 suggest a seasonal AR(3) component. 

* Therefore, we can begin with an ARIMA(2,0,0)(3,1,0)[12] indicating one seasonal difference on the log turnover series, non-seasonal AR(2) and seasonal AR(3) components. 

```{r}
arima_fit_1 <- train %>% model(ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,0)))

arima_fit_1 %>% report()

arima_fit_1 %>% gg_tsresiduals()

arima_fit_1 %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 5) %>% select(lb_pvalue)
```

* Fitting ARIMA(2,0,0)(3,1,0)[12] on the log turnover data (i.e. before applying seasonal differencing), we see that the ACF still has several spikes outside the boundaries, suggesting uncaptured autocorrelations. Moreover, we also reject the null at 5% confidence interval for the Ljung-Box test, suggesting that the residuals do not resemble a white noise process. 

* We will further refine this model by trying out different combinations of (P,Q) with upper limit of 3 for each and compare based on their AICc values. 

```{r}
arima_fit_2 <- train %>% 
  model(arima_1 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,1)),
        arima_2 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,2)),
        arima_3 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,3)),
        arima_4 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,0)),
        arima_5 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,1)),
        arima_6 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,2)),
        arima_7 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,3)),
        arima_8 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,0)),
        arima_9 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,1)),
        arima_10 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,2)),
        arima_11 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,3)),
        arima_12 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,0)),
        arima_13 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,1)),
        arima_14 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,2)),
        arima_15 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,3))) 

glance(arima_fit_2) %>% select(.model, AICc) %>% arrange(AICc)
```

* At this stage, arima_7, which is ARIMA(2,0,0)(2,1,3)[12], has the lowest AICc. 

```{r}
arima_fit_2 %>% select(arima_7) %>% report() 

arima_fit_2 %>% select(arima_7) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 7) %>% select(lb_pvalue)

arima_fit_2 %>% select(arima_7) %>% gg_tsresiduals()
```

* We see that this model still has some significant and nearly significant spikes in its ACF, especially at lag 2. We also reject the null for the Ljung-Box test. Nevertheless, we can definitely see some improvements in the ACF compared to the original model before refining. Therefore, we will further refine this model by trying out other (p,q) combinations to find one that can fully capture all the autocorrelations in the residuals. 

```{r}
arima_fit_3 <- train %>% 
  model(arima_1 = ARIMA(log(turnover) ~ 0 + pdq(2,0,1) + PDQ(2,1,3)),
        arima_2 = ARIMA(log(turnover) ~ 0 + pdq(2,0,2) + PDQ(2,1,3)),
        arima_3 = ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3)))

glance(arima_fit_3) %>% select(.model, AICc) %>% arrange(AICc)
```

* After futher refining, the model with the lowest AICc is now ARIMA(2,0,2)(2,1,3)[12]. 

```{r}
arima_fit_3 %>% select(arima_2) %>% report()

arima_fit_3 %>% select(arima_2) %>% gg_tsresiduals()

arima_fit_3 %>% select(arima_2) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 9) %>% select(lb_pvalue)
```

* We see that all the spikes are now within the boundaries, and we also do not reject the null for the Ljung-Box test with 24 lags and 9 dof, at 5% significance level. However, the p-value for this test is very borderline, at 0.05070177. We will see if the other two models are any better than this one in terms of ACF and p-value for the Ljung-Box test. 

* The second best model is ARIMA(2,0,3)(2,1,3)[12]:

```{r}
arima_fit_3 %>% select(arima_3) %>% report()

arima_fit_3 %>% select(arima_3) %>% gg_tsresiduals()

arima_fit_3 %>% select(arima_3) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 10) %>% select(lb_pvalue)
```

* This model's ACF also has all the spikes within boundaries. Additionally, the p-value for its Ljung-Box test with 24 lags and 10 dof at 5% interval is higher, at 0.06232267, and no longer borderline as in the previous case. 

* Let's also look at the remaining model: 

```{r}
arima_fit_3 %>% select(arima_1) %>% report()

arima_fit_3 %>% select(arima_1) %>% gg_tsresiduals()

arima_fit_3 %>% select(arima_1) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 8) %>% select(lb_pvalue)
```
* For this model, despite having all spikes within boundaries in the ACF, we still reject the null for the Ljung-Box test. 

* Since the best two models, ARIMA(2,0,2)(2,1,3)[12] and ARIMA(2,0,3)(2,1,3)[12], are quite comparable in terms of AICc, ACF and Ljung-Box test, to decide which one to choose, let's look at how they perform on the test set, alongside all the ARIMA models we've considered so far. Before doing so, let's also look at some ARIMA models generated automatically to see how they perform on the train set: 

* Some automatic models: 

1. With approximation = FALSE and stepwise = FALSE: 

```{r}
arima_auto_1 <- train %>% model(ARIMA(log(turnover) ~ 0 + pdq(d = 0) + PDQ(D = 1), approximation = FALSE, stepwise = FALSE)) 

arima_auto_1 %>% report()

arima_auto_1 %>% gg_tsresiduals()

arima_auto_1 %>% augment() %>% features(.resid, ljung_box, dof = 5, lag = 24) %>% select(lb_pvalue)
```

2. With approximation = TRUE and stepwise = TRUE: 

```{r}
arima_auto_2 <- train %>% model(ARIMA(log(turnover) ~ 0 + pdq(d = 0) + PDQ(D =1))) 

arima_auto_2 %>% report()

arima_auto_2 %>% gg_tsresiduals()

arima_auto_2 %>% augment() %>% features(.resid, ljung_box, dof = 6, lag = 24) %>% select(lb_pvalue)
```

* The two automatic models suggested are actually worse than the ones we have looked at manually. Their AICc values are higher, their ACFs have many spikes outside the boundaries and we also reject the null for their Ljung-Box tests. 

* Evaluating all potential ARIMA models we have looked at so far on the test set: 

```{r}
arima_fit_4 <- train %>% 
  model(arima_0 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,0)),
        arima_1 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,1)),
        arima_2 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,2)),
        arima_3 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,3)),
        arima_4 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,0)),
        arima_5 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,1)),
        arima_6 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,2)),
        arima_7 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,3)),
        arima_8 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,0)),
        arima_9 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,1)),
        arima_10 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,2)),
        arima_11 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,3)),
        arima_12 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,0)),
        arima_13 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,1)),
        arima_14 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,2)),
        arima_15 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,3)), 
        arima_16 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,1)),
        arima_17 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,2)),
        arima_18 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(3,1,3)),
        arima_19 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,0)),
        arima_20 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,1)),
        arima_21 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,2)),
        arima_22 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(2,1,3)),
        arima_23 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,0)),
        arima_24 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,1)),
        arima_25 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,2)),
        arima_26 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(1,1,3)),
        arima_27 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,0)),
        arima_28 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,1)),
        arima_29 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,2)),
        arima_30 = ARIMA(log(turnover) ~ 0 + pdq(2,0,0) + PDQ(0,1,3)), 
        best_3 = ARIMA(log(turnover) ~ 0 + pdq(2,0,1) + PDQ(2,1,3)),
        best_1 = ARIMA(log(turnover) ~ 0 + pdq(2,0,2) + PDQ(2,1,3)),
        best_2 = ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3)))

arima_fit_4 %>% forecast(h = 24) %>% accuracy(myseries) %>% arrange(RMSE)
```

* When evaluating on the test set, the best two models when it comes to RMSE are: 

- ARIMA(2,0,1)(2,1,3)[12]
- ARIMA(2,0,3)(2,1,3)[12]

* However, we can recall from fitting the models on the training set that ARIMA(2,0,1)(2,1,3)[12], despite having all spikes within boundaries on the ACF, still rejects the null of the Ljung-Box test. 

* **ARIMA(2,0,3)(2,1,3)[12] seems like the best model for our data for reasons as follows:** 

1. It has the second lowest AICc of all the models we have considered. 

2. Its ACF has all spikes within boundaries and we also do not reject the null for the Ljung-Box test with 24 lags, suggesting there are no autocorrelations remaining in the residuals and the residuals are also indistinguishable from a white noise process. 

3. It performed really well on the test set, ranking second when it comes to RMSE. 

# 4. Analyses of the best ETS and ARIMA models: 

**The chosen model from each class are:**

- ETS(M,Ad,M)
- ARIMA(2,0,3)(2,1,3)[12]

## ETS(M,Ad,M):

* **ETS - Parameter estimates:** 

```{r}
best <- train %>% model(best_ets = ETS(turnover ~ error("M") + trend("Ad") + season("M")), 
                best_arima = ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3))) 

best %>% select(best_ets) %>% tidy()
```

* **ETS - Residual diagnostics:** 

```{r}
best %>% select(best_ets) %>%
  gg_tsresiduals() +
  labs(title = "Residual diagnostic plots: New South Wales retail trade turnover", subtitle = "Original data - with ETS(M,Ad,M)")
```

* The mean of the residuals is close to zero. Deviations from the mean are roughly constant through time, despite some slightly stronger fluctuations. 

* The ACF shows many spikes outside the boundaries, suggesting that there are still uncaptured autocorrelations remaining in the residuals that can be used to improve the forecasts.

* The histogram of the residuals looks roughly normal. 

```{r}
best %>% select(best_ets) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 17)  %>% select(lb_pvalue) 
```

* We also reject the null for the Ljung-Box test with 24 lags and 16 dof, suggesting that the residuals do not resemble a white noise process, which will affect the reliability of the prediction intervals. 

* **ETS - Forecast + evaluate on the test set:** 

```{r}
best %>% select(best_ets) %>% forecast(h = 24) %>% autoplot(myseries_recent, alpha = 0.5, level = 80) + 
   ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M)")
```

* The point forecasts do capture the shape of the actual turnover, however, the gaps between them are noticeable.

```{r}
best %>% select(best_ets) %>% forecast(h = 24) %>% accuracy(myseries)
```

## ARIMA(2,0,3)(2,1,3)[12]

* **ARIMA - Parameter estimates:** 

```{r}
best %>% select(best_arima) %>% tidy()
```

* **ARIMA - Residual diagnostics:** 

```{r}
best %>% select(best_arima) %>%
  gg_tsresiduals() +
  labs(title = "Residual diagnostic plots: New South Wales retail trade turnover", subtitle = "Logged data - with - ARIMA(2,0,3)(2,1,3)[12]
")
```

* The mean of the residuals is close to zero and time plot of the residuals shows that the variation of the residuals stay much the same across the historical data, except for one cluster of slighly larger deviations which is negligible.

* ACF has all spikes well within boundaries, which means that the forecasts produced seem to have accounted for all available information and there are no significant autocorrelations left in the residuals that can be utilised. 

* The histogram looks roughly normal, perhaps with a slightly heavier left tail which should not affect the prediction intervals by much. 

```{r}
best %>% select(best_arima) %>% augment() %>% features(.resid, ljung_box, lag = 24, dof = 10)  %>% select(lb_pvalue)
```

* We do not reject the null for the Ljung-Box test with 24 lags and 10 dof, suggesting that the residuals are indistinguishable from a white noise process. Therefore, the PIs are reliable. 

* **ARIMA - Forecast + evaluate on the test set:** 

```{r}
best %>% select(best_arima) %>% forecast(h = 24) %>% autoplot(myseries_recent, alpha = 0.5, level = 80) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ARIMA(2,0,3)(2,1,3)[12]")
```

* The point forecasts capture the shape of the actual data really well, with smaller gaps when compared to those produced by ETS. 

```{r}
best %>% select(best_arima) %>% forecast(h = 24) %>% accuracy(myseries)
```


# 5. Comparison of the results from ETS and ARIMA models:

* **Looking at forecasts and prediction interval for ETS and ARIMA models jointly:** 

```{r}
best %>% forecast(h = 24) %>% autoplot(myseries_recent, alpha = 0.5, level = 80) + 
   ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(A,A,M) and ARIMA(2,0,3)(2,1,3)[12]")
```

* Clearly, ARIMA's forecasts more closely resemble the actual realizations of turnover. The PIs for these two models are comparable in terms of width. However, ETS' 80% PIs are more oriented downward, due to its underestimating the actual turnover. Actual turnover values fall within the PIs for both models. 

```{r}
arima_fit <- train %>% model(arima = (ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3))))

ets_fit <- train %>% model(ets = ETS(turnover ~ error("M") + trend("Ad") + season("M")))


bind_rows(
  arima_fit %>% accuracy(),
  ets_fit %>% accuracy(),
  arima_fit %>% forecast(h = "2 years") %>%
    accuracy(myseries),
  ets_fit %>% forecast(h = "2 years") %>%
    accuracy(myseries)
)
```

- **ACF:** ETS still displays multiple significant lags whereas ARIMA has all spikes within the boundaries. This means forecasts from ARIMA have captured all the useful information that might have been leaked to the residuals as is the case with ETS. We can still use the ETS model for forecasting, but its PIs might not be accurate. 

- **Ljung-Box test with 24 lags:** we reject the null for ETS model. In contrast, we do not reject the null for the ARIMA model's test. Residuals from ARIMA model resemble a white noise process while those from ETS do not. This suggests that PIs for ARIMA are more reliable than those for ETS. 

- **Forecasts:** ARIMA performs better both on the train and test set, regardless of which measure is being used. The PIs for ARIMA and ETS are comparable in terms of width, but point forecasts for ARIMA are closer to the actual turnover values than for ETS. 

* Therefore, **ARIMA seems to give better forecasts for my series** when training on the train set and evaluating on the test set.

* ARIMA has also captured all the autocorrelations in the residuals while ETS has not. 

# 6. Two-year forecasts - from Jan 2018 to Dec 2019.

```{r}
best <- myseries %>% model(best_ets = ETS(turnover ~ error("M") + trend("Ad") + season("M")),
                           best_arima = ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3)))
```

## Forecasting with ETS: 

* **Point forecasts and 80% prediction intervals:**

```{r}
best %>% select(best_ets) %>% forecast(h = 24) %>% hilo(80)
```

* **Forecasting plot:**

```{r}
best %>% select(best_ets) %>% forecast(h = 24) %>% autoplot(myseries_recent, alpha = 0.5, level = 80) +
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M)")
```

## Forecasting with ARIMA: 

* **Point forecasts and 80% prediction intervals:**

```{r}
best %>% select(best_arima) %>% forecast(h = 24) %>% hilo(80)
```

* **Forecasting plot:**

```{r}
best %>% select(best_arima) %>% forecast(h = 24) %>% autoplot(myseries_recent, level = 80, alpha = 0.5) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ARIMA(2,0,3)(2,1,3)[12]")
```

* **Forecasting plot with ETS and ARIMA jointly:**

```{r}
best %>% forecast(h = 24) %>% autoplot(myseries_recent, level = 80, alpha = 0.5) +
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M) and ARIMA(2,0,3)(2,1,3)[12]")
```

# 7. Compare two-year forecasts, from Jan 2018 to Dec 2019, with ABS data. 

```{r}
library(readabs)
abs_series <- readabs::read_abs(cat_no = "8501.0", tables = "11") %>%
  filter(series_id == "A3349401C") %>%
  select(date, value) %>% 
  rename(month = date, turnover = value) %>% 
  filter(month < yearmonth("2020 Jan"))
```

```{r}
abs_series$month <- format(as.Date(abs_series$month), "%Y %b")

abs_series$month <- abs_series$month %>% yearmonth()

abs_series <- abs_series %>% as_tsibble(index = month)

abs_recent <- abs_series %>% filter(month > yearmonth("2015 Dec"), month < yearmonth("2020 Jan"))

abs_forecast <- abs_series %>% filter(month > yearmonth("2017 Dec"), month < yearmonth("2020 Jan"))
```

```{r}
best %>% forecast(h = 24) %>% autoplot(abs_recent, alpha = 0.5, level = 80) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M) and ARIMA(2,0,3)(2,1,3)[12]")
```

```{r}
best %>% forecast(h = 24) %>% autoplot(abs_forecast, alpha = 0.5, level = 80) + 
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "2-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M) and ARIMA(2,0,3)(2,1,3)[12]")
```

* Both models produce forecasts that capture the shape of the actual turnover really well. Their prediction intervals are also comparable in terms of width, and both contain the actual values. However, we can clearly see that ARIMA forecasts follow more closely the actual turnover values than those of ETS.  

```{r}
fit_arima <- myseries %>% model(best_arima = (ARIMA(log(turnover) ~ 0 + pdq(2,0,3) + PDQ(2,1,3))))

fit_ets <- myseries %>% model(best_ets = ETS(turnover ~ error("M") + trend("Ad") + season("M")))


bind_rows(
  fit_arima %>% accuracy(),
  fit_ets %>% accuracy(),
  fit_arima %>% forecast(h = "2 years") %>%
    accuracy(abs_series),
  fit_ets %>% forecast(h = "2 years") %>%
    accuracy(abs_series)
)
```

* ARIMA is clearly the better model judging by both the train and test sets, regardless of which measure is used. 

* **Point forecasts and prediction intervals from ETS(M,Ad,M):**

```{r, fig.align = 'center'}
fc80 = best %>% select(best_ets) %>% forecast(h = 24) %>% hilo() 

table = fc80 %>% select(month, turnover) 

int80 = fc80$`80%` 

lower = int80$.lower
upper = int80$.upper

table = tibble(table, lower, upper) 

head(table,24)
```

* **Point forecasts and prediction intervals from ARIMA(2,0,3)(2,1,3)[12]:**

```{r, fig.align = 'center'}
fc80 = best %>% select(best_arima) %>% forecast(h = 24) %>% hilo() 

table = fc80 %>% select(month, turnover) 

int80 = fc80$`80%` 

lower = int80$.lower
upper = int80$.upper

table = tibble(table, lower, upper) 

head(table, 24)
```

* **Therefore, we can conclude that ARIMA(2,0,3)(2,1,3)[12] is the better model from a forecasting perspective than ETS(M,Ad,M) for our data.**

# 8. A discussion of benefits and limitations of the models for your data.

## ETS model: 

* **Benefits:** 

1. We do not need to perform transformation or differencing on the turnover data before fitting the ETS model. This means eliminating the unit root tests step, which are prone to errors if not handled carefully.  

2. There is a small selection of potential ETS models to choose from, making it easy to evaluate between the few appropriate combinations of E, T and S components. 

3. ETS(M,Ad,M) features a damped trend component. This will be useful when we expect the data to grow at a slower rate in the future. 

* **Limitations:** 

1. The ETS model is more cumbersome as it involves estimating 17 parameters. Having more parameters also take away some dof when it comes to doing the Ljung-Box test. 

2. The residuals display significant autocorrelations remaining that have not been captured when computing forecasts. The residuals also do not resemble a white noise series, which means the PIs might not be reliable. 

3. The damped trend component might actually be inappropriate if we expect the trend of the data to continue increasing going forward due to increases in population. If that is the case, then an ETS(M,A,M) might be more appropriate as it will not underestimate the turnover like ETS(M,Ad,M) does. 

## ARIMA model: 

* **Benefits:** 

1. Residuals diagnostics for the ARIMA model show that it has fully captured all the persistence, which means there is no useful information left in the residuals that can be used in forecasting future turnover. The residuals also resemble a white noise process, which means the PIs are reliable. 

2. ARIMA model produced more accurate forecasts than ETS both on the train and test set, regardless of which measure is being used.
 

3. ARIMA model also involves estimating fewer parameters, which is not only more computationally efficient, less subject to error but also does not take away too many dof when it comes to doing the Ljung-Box test. 

* **Limitations:** 

1. Clearly, there is an infinite number of ARIMA models to choose from. In this case, despite setting an upper limit of 3 for p, q, P and Q, we still had to train and evaluate a lot more ARIMA models before arriving at the optimal one. This process sure can be automated, but we have seen that the automatic models are actually not the best ones, perhaps for this particular series (most of the time, the automatic process can actually be of great help). Choosing an appropriate ARIMA model, hence, is more manually and computationally demanding. 

2. We also need to log transform the data to deal with non-stationary mean, as well as perform unit-root tests to determine if we also need to first difference and/or seasonal difference the data. 

## Overall: 

* In the long term, we find that forecasts from the best ARIMA model make more sense **for this particular data series** than those from the best ETS model: 

```{r}
best %>% forecast(h = 96) %>% autoplot(abs_series, alpha = 0.5, level = 80) +
  ylab("Turnover (million AUD)") + 
  xlab("Time") +
  theme_light() +
  labs(title = "8-year forecasts for NSW's retail turnover", subtitle = "Pharmaceutical, cosmetic and toiletry goods - with ETS(M,Ad,M) and ARIMA(2,0,3)(2,1,3)[12]")
```

# Reference: 

Hyndman, R.J., & Athanasopoulos, G. (2019) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on <07.06.2020>.


